{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Week4-Exercise-Shakespeare-Question.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah4ZCtVhFVoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "f97e6e94-8118-4d0d-dac4-2aff016fb2c4"
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.16.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ab22671a-8f6b-47e4-a351-a92560ecde03"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-27 15:52:37--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-07-27 15:52:37 (107 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "e9660631-0d88-49f9-f717-79f38f540748"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words,100,input_length = max_sequence_len-1))\n",
        "model.add(LSTM(150,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(total_words/2,activation='relu',kernel_regularizer = regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "# Pick an optimizer\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "unified_lstm_2 (UnifiedLSTM) (None, 10, 150)           150600    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 150)           0         \n",
            "_________________________________________________________________\n",
            "unified_lstm_3 (UnifiedLSTM) (None, 64)                55040     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1605)              104325    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 5,787,931\n",
            "Trainable params: 5,787,931\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03c77e1f-ade0-4692-dd4d-bb2322e4552a"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15462/15462 [==============================] - 54s 3ms/sample - loss: 6.8955 - accuracy: 0.0224\n",
            "Epoch 2/100\n",
            "15462/15462 [==============================] - 54s 3ms/sample - loss: 6.5103 - accuracy: 0.0209\n",
            "Epoch 3/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 6.4398 - accuracy: 0.0222\n",
            "Epoch 4/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 6.3711 - accuracy: 0.0259\n",
            "Epoch 5/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 6.2777 - accuracy: 0.0305\n",
            "Epoch 6/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 6.1882 - accuracy: 0.0314\n",
            "Epoch 7/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 6.1207 - accuracy: 0.0374\n",
            "Epoch 8/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 6.0513 - accuracy: 0.0392\n",
            "Epoch 9/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.9928 - accuracy: 0.0399\n",
            "Epoch 10/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.9395 - accuracy: 0.0422\n",
            "Epoch 11/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.8883 - accuracy: 0.0453\n",
            "Epoch 12/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 5.8400 - accuracy: 0.0459\n",
            "Epoch 13/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 5.7808 - accuracy: 0.0490\n",
            "Epoch 14/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.7159 - accuracy: 0.0549\n",
            "Epoch 15/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.6503 - accuracy: 0.0570\n",
            "Epoch 16/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.5848 - accuracy: 0.0609\n",
            "Epoch 17/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.5198 - accuracy: 0.0639\n",
            "Epoch 18/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.4545 - accuracy: 0.0678\n",
            "Epoch 19/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.3884 - accuracy: 0.0715\n",
            "Epoch 20/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.3242 - accuracy: 0.0773\n",
            "Epoch 21/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.2563 - accuracy: 0.0803\n",
            "Epoch 22/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.1868 - accuracy: 0.0843\n",
            "Epoch 23/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.1120 - accuracy: 0.0891\n",
            "Epoch 24/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 5.0454 - accuracy: 0.0931\n",
            "Epoch 25/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.9760 - accuracy: 0.0993\n",
            "Epoch 26/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.8968 - accuracy: 0.1054\n",
            "Epoch 27/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.8255 - accuracy: 0.1102\n",
            "Epoch 28/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.7581 - accuracy: 0.1157\n",
            "Epoch 29/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.6975 - accuracy: 0.1195\n",
            "Epoch 30/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.6260 - accuracy: 0.1247\n",
            "Epoch 31/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.5568 - accuracy: 0.1328\n",
            "Epoch 32/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.4913 - accuracy: 0.1382\n",
            "Epoch 33/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 4.4273 - accuracy: 0.1445\n",
            "Epoch 34/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 4.3649 - accuracy: 0.1502\n",
            "Epoch 35/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 4.3120 - accuracy: 0.1533\n",
            "Epoch 36/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 4.2458 - accuracy: 0.1619\n",
            "Epoch 37/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 4.1789 - accuracy: 0.1669\n",
            "Epoch 38/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 4.1233 - accuracy: 0.1713\n",
            "Epoch 39/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 4.0672 - accuracy: 0.1830\n",
            "Epoch 40/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 4.0158 - accuracy: 0.1878\n",
            "Epoch 41/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.9571 - accuracy: 0.1984\n",
            "Epoch 42/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.8972 - accuracy: 0.2083\n",
            "Epoch 43/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.8421 - accuracy: 0.2147\n",
            "Epoch 44/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.7905 - accuracy: 0.2233\n",
            "Epoch 45/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 3.7440 - accuracy: 0.2300\n",
            "Epoch 46/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.6892 - accuracy: 0.2421\n",
            "Epoch 47/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.6394 - accuracy: 0.2546\n",
            "Epoch 48/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.5957 - accuracy: 0.2591\n",
            "Epoch 49/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.5563 - accuracy: 0.2659\n",
            "Epoch 50/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.4987 - accuracy: 0.2754\n",
            "Epoch 51/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.4607 - accuracy: 0.2866\n",
            "Epoch 52/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 3.4160 - accuracy: 0.2967\n",
            "Epoch 53/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.3745 - accuracy: 0.2989\n",
            "Epoch 54/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.3218 - accuracy: 0.3102\n",
            "Epoch 55/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.2904 - accuracy: 0.3183\n",
            "Epoch 56/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 3.2456 - accuracy: 0.3238\n",
            "Epoch 57/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 3.1994 - accuracy: 0.3356\n",
            "Epoch 58/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 3.1608 - accuracy: 0.3479\n",
            "Epoch 59/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 3.1306 - accuracy: 0.3487\n",
            "Epoch 60/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.0894 - accuracy: 0.3627\n",
            "Epoch 61/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.0497 - accuracy: 0.3650\n",
            "Epoch 62/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 3.0153 - accuracy: 0.3776\n",
            "Epoch 63/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.9807 - accuracy: 0.3861\n",
            "Epoch 64/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.9504 - accuracy: 0.3920\n",
            "Epoch 65/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.9102 - accuracy: 0.3976\n",
            "Epoch 66/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.8763 - accuracy: 0.4047\n",
            "Epoch 67/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.8380 - accuracy: 0.4187\n",
            "Epoch 68/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.8047 - accuracy: 0.4227\n",
            "Epoch 69/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.7749 - accuracy: 0.4300\n",
            "Epoch 70/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.7461 - accuracy: 0.4378\n",
            "Epoch 71/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.7070 - accuracy: 0.4441\n",
            "Epoch 72/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.6678 - accuracy: 0.4540\n",
            "Epoch 73/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.6564 - accuracy: 0.4618\n",
            "Epoch 74/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.6118 - accuracy: 0.4670\n",
            "Epoch 75/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.5946 - accuracy: 0.4734\n",
            "Epoch 76/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.5676 - accuracy: 0.4735\n",
            "Epoch 77/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.5367 - accuracy: 0.4808\n",
            "Epoch 78/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.5031 - accuracy: 0.4920\n",
            "Epoch 79/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.4807 - accuracy: 0.4960\n",
            "Epoch 80/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.4542 - accuracy: 0.5009\n",
            "Epoch 81/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.4163 - accuracy: 0.5083\n",
            "Epoch 82/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.4034 - accuracy: 0.5159\n",
            "Epoch 83/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.3702 - accuracy: 0.5221\n",
            "Epoch 84/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.3403 - accuracy: 0.5315\n",
            "Epoch 85/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.3208 - accuracy: 0.5374\n",
            "Epoch 86/100\n",
            "15462/15462 [==============================] - 51s 3ms/sample - loss: 2.3018 - accuracy: 0.5402\n",
            "Epoch 87/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.2900 - accuracy: 0.5403\n",
            "Epoch 88/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.2566 - accuracy: 0.5468\n",
            "Epoch 89/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.2312 - accuracy: 0.5521\n",
            "Epoch 90/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.2028 - accuracy: 0.5634\n",
            "Epoch 91/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.1797 - accuracy: 0.5695\n",
            "Epoch 92/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.1647 - accuracy: 0.5709\n",
            "Epoch 93/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.1480 - accuracy: 0.5761\n",
            "Epoch 94/100\n",
            "15462/15462 [==============================] - 52s 3ms/sample - loss: 2.1293 - accuracy: 0.5755\n",
            "Epoch 95/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 2.1001 - accuracy: 0.5861\n",
            "Epoch 96/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 2.0917 - accuracy: 0.5808\n",
            "Epoch 97/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 2.0585 - accuracy: 0.5938\n",
            "Epoch 98/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 2.0414 - accuracy: 0.6022\n",
            "Epoch 99/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 2.0347 - accuracy: 0.5962\n",
            "Epoch 100/100\n",
            "15462/15462 [==============================] - 53s 3ms/sample - loss: 1.9946 - accuracy: 0.6120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "b2788535-f1e6-4041-8b1f-0493f97258b1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-31858f16e7b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IjeF21bJeks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}